{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1528c473",
   "metadata": {},
   "source": [
    "<font size=\"10\">\n",
    "    <div align=\"center\">\n",
    "        Técnicas y algoritmos de búsqueda\n",
    "    </div>\n",
    "</font>\n",
    "<font size=\"6\">\n",
    "    <div align=\"center\">\n",
    "        Informe de la práctica 3\n",
    "    </div>\n",
    "    <br>\n",
    "\n",
    "</font>\n",
    "<font size=\"5\">\n",
    "    <div align=\"center\">\n",
    "        Gabriel Niculescu Ruso \n",
    "    </div>\n",
    "    <div align=\"center\">\n",
    "        Carlos Molera Canals\n",
    "    </div>\n",
    "    <div align=\"center\">\n",
    "        Jose Francisco Pérez Mompeán\n",
    "    </div>\n",
    "</font>\n",
    "<font size=\"5\">\n",
    "    <div align=\"right\">\n",
    "        29/05/2025\n",
    "    </div>\n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c266bd",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <hi><font size=\"9\"><strong>Indice</strong></font></hi>\n",
    "    <ol>\n",
    "        <li><font size=\"4\">Alpha-Beta</font></li>\n",
    "        <li><font size=\"4\">Tabla de transposición</font></li>\n",
    "        <li><font size=\"4\">Función de Evaluación</font></li>\n",
    "        <li><font size=\"4\">La red</font></li>\n",
    "        <li><font size=\"4\">Testing</font></li>\n",
    "    </ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66219030",
   "metadata": {},
   "source": [
    "## **1. ALPHA-BETA**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04291805",
   "metadata": {},
   "source": [
    "En esta sección exploraremos la técnica de poda de Alpha-Beta. Un optimizador importante del algoritmo Minimax para la toma de decisiones en juegos. Se cubrirán los siguientes aspectos:\n",
    "1. Introducción general al concepto  \n",
    "\n",
    "2. Mecanismo y principios fundamentales  \n",
    "\n",
    "3. Algoritmo detallado: pseudocódigo  \n",
    "\n",
    "4. Poda Alpha-Beta en el contexto de Pacman  \n",
    "\n",
    "5. Beneficios de Alpha-Beta  \n",
    "\n",
    "6. Inconvenientes \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc2044d",
   "metadata": {},
   "source": [
    "### **1.1. Introducción general al concepto**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b3acb6",
   "metadata": {},
   "source": [
    "La poda de Alpha-Beta es una técnica de optimización para el algoritmo de minimax el cual es un algoritmo de  búsqueda que busca disminuir el número de nodos que son explorados por el algoritmo minimax en su árbol de búsqueda."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed26fe77",
   "metadata": {},
   "source": [
    "### **1.2. Mecanismo y principios fundamentales**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebade6b",
   "metadata": {},
   "source": [
    "* Con Alpha-beta podemos lograr el mismo resultado que minimax pero evaluando menos nodos. Esto es posible porque la poda de alpha-beta corta ramas del árbol de búsqueda que posiblemente no pueden influir en la decisión final, solo lo hace más rápido.\n",
    "* La eficiencia de la poda alpha-beta depende en gran medida del orden en que se evalúan los movimientos. Un ordenamiento óptimo puede llevar a una poda enorme, mientras que un ordenamiento en el peor de los casos puede llevar a no podar nada.\n",
    "* Mantiene $2$ valores, $\\alpha$ y $\\beta$, que se representan la puntuación máxima y mínima que el jugador tiene asegurada, respectivamente.\n",
    "*   Alpha se asocia con el jugador maximizador (a menudo llamado MAX), y beta se asocia con el jugador minimizador (a menudo llamado MIN).  \n",
    "\n",
    "*   Inicialmente, alfa es infinito negativo y beta es infinito positivo.\n",
    "\n",
    "Tabla de resumen:\n",
    "\n",
    "| Término | Jugador | Descripción | Valor inicial |\n",
    "| ------- | ------- | ----------- | ------------- |\n",
    "| $\\alpha$  | Max  |Mejor puntuación (más alta) garantizada para MAX a lo largo del camino actual.         |$-\\infty$          |\n",
    "| $\\beta$  | Min  |Mejor puntuación (más baja) garantizada para MIN a lo largo del camino actual.        |$+\\infty$           |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8857e886",
   "metadata": {},
   "source": [
    "### **1.3. Algoritmo detallado: pseudocódigo**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42d5604",
   "metadata": {},
   "source": [
    "El siguiente pseudocódigo ilustra la lógica fundamental de la búsqueda con poda Alfa-Beta:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580624dc",
   "metadata": {},
   "source": [
    "\n",
    "\\begin{equation} \\nonumber\n",
    "\\begin{array}{l}\n",
    "\\text{Input: Root MAX node } J \\leftarrow s \\\\\n",
    "\\text{Output: Optimal Minimax Value } V(J). \\\\\n",
    "\\\\\n",
    "\\text{1. if } J \\text{ is terminal then return } V(J) = e(J). \\\\\n",
    "\\text{2. for } k = 1, 2, \\ldots, b: \\\\\n",
    "\\hspace{10pt} \\text{1. Generate } J_k \\text{ the } k\\text{-th successor of } J \\\\\n",
    "\\hspace{10pt} \\text{2. Evaluate } V(J_k) \\; \\text{[recursive call]} \\\\\n",
    "\\hspace{10pt} \\text{3. if } k = 1, \\text{ set } CV(J) \\leftarrow V(J_1) \\\\\n",
    "\\hspace{10pt} \\text{4. else:} \\\\\n",
    "\\hspace{20pt} \\text{1. if } J \\text{ is MAX then set } CV(J) \\leftarrow \\max[CV(J), V(J_k)] \\\\\n",
    "\\hspace{20pt} \\text{2. if } J \\text{ is MIN then set } CV(J) \\leftarrow \\min[CV(J), V(J_k)] \\\\\n",
    "\\text{3. return } V(J) = CV(J)\n",
    "\\end{array}\n",
    "\\end{equation}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d255c2ce",
   "metadata": {},
   "source": [
    "### **1.4. Poda Alpha-Beta en el contexto de Pacman**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0423e2",
   "metadata": {},
   "source": [
    "En el contexto de Pacman, la poda de alpha-beta se utiliza para determinar el mejor movimiento de pacman considerando las respuestas de los fantasmas. Pacman es el jugador max $($ tratando de obtener el $score$ más alto $)$ y los fantasmas son los jugadores min $($ tratando de terminar el juego o minimizar el $score$ de pacman $)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312a794a",
   "metadata": {},
   "source": [
    "* **Evaluación de estado:** \n",
    "A cada estado del juego, es decir, donde está pacman, los fantasmas, la comida restante, etc. Se le asigna una puntuación mediante una función de avaluación explicada posteriormente. La poda alpha-beta utiliza estas puntuaciones para decidir qué partes del árbol del juego explorar.  \n",
    "\n",
    "En nuestra implementación, la función `alphabeta` toma el estado actual del juego, la profundidad de búsqueda deseada, alpha, beta y el jugador actual, ya esa como Min o Max.  \n",
    "Durante la búsqueda, si alpha se vuelve mayor o igual a beta, significa que la rama actual puede ser podada. Esto se debe a que el jugador max ya ha encontrado un movimiento que garantiza una puntuación mayor o igual a alpha y el jugador min ya ha encontrado un movimiento que garantiza una puntuación menor o igual a beta. Si $\\alpha \\geq \\beta$, la posición actual no puede ser el resultado del mejor juego de ambos jugadores y, por lo tanto, no necesita ser explorada más a fondo.  \n",
    "\n",
    "\n",
    "<div align=\"center\">\n",
    "<h1>Alpha-Beta<h1>\n",
    "    <img src=\"../fotos/alpha_beta_funcion.png\" style=\"width: 1300px;\">\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc32b000",
   "metadata": {},
   "source": [
    "Con sus respectivos jugadores de Min y Max:  \n",
    "  \n",
    "\n",
    "<div style=\"width: 100%; text-align: center;\">\n",
    "    <div style=\"float: none; display: inline-block;\">\n",
    "    <h1>Max<h1>\n",
    "        <img src=\"../fotos/alpha_beta_funcion_max.png\" style=\"width: 900px;\">\n",
    "    </div>\n",
    "    <div style=\"float: none; display: inline-block;\">\n",
    "    <h1> Min <h1>\n",
    "        <img src=\"../fotos/alpha_beta_funcion_min.png\" style=\"width: 900px;\">\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1a589a",
   "metadata": {},
   "source": [
    "### **1.5. Beneficios de Alpha-Beta**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4c1616",
   "metadata": {},
   "source": [
    "*   **Espacio de búsqueda reducido:** Reduce significativamente el número de nodos a evaluar en el árbol de búsqueda en comparación con el minimax simple.  \n",
    "\n",
    "*   **Decisiones más rápidas:** Conduce a una toma de decisiones más rápida, especialmente en juegos con grandes factores de ramificación o requisitos de búsqueda profunda.  \n",
    "*   **Viabilidad para búsquedas más profundas:** Permite búsquedas más profundas dentro de los mismos límites de tiempo computacional, lo que potencialmente lleva a un mejor juego.    \n",
    "  \n",
    "\n",
    "Aquí un ejemplo de la poda de alpha-beta respecto a minimax normal (Los nodos rojos son Max y los azules Min), todo esto con profundidad $4$:  \n",
    "\n",
    "<div style=\"width: 100%; text-align: center;\">\n",
    "<h1> AlphaBeta<h1>\n",
    "    <div style=\"float: none; display: inline-block;\">\n",
    "        <img src=\"../fotos/alphabeta.png\" style=\"width: 900px;\">\n",
    "    </div>\n",
    "   <h1> Minimax<h1>\n",
    "    <div style=\"float: none; display: inline-block;\">\n",
    "        <img src=\"../fotos/minimax.png\" style=\"width: 900px;\">\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b92d05d",
   "metadata": {},
   "source": [
    "### **1.6. Inconvenientes**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b385f0",
   "metadata": {},
   "source": [
    "*   **Complejidad:** El algoritmo es ligeramente más complejo de implementar que el minimax simple debido a la gestión de los valores alfa y beta.  \n",
    "*   **Dependencia del orden de los movimientos:** La efectividad de la poda depende en gran medida del orden en que se examinan los nodos posteriores. Si se examinan buenos movimientos tempranos, ocurre más poda.\n",
    "*   **Necesidad de una buena función de evaluación:** El rendimiento de la poda alfa-beta en pacman depende críticamente de la función de evaluación. Si la función no evalúa con el estado del juego, el algoritmo podría tomar decisiones subóptimas. Por ejemplo, una función de evaluación que solo considera la puntuación podría llevar a pacman a una trampa si no pondera también factores como la proximidad a los fantasmas, la distancia a la comida más cercana o si las cápsulas están activas. Una buena función de evaluación en pacman debería considerar:  \n",
    "\n",
    "    *   Puntuación actual del juego.\n",
    "    *   Distancia a los fantasmas.  \n",
    "\n",
    "    *   Distancia a la comida más cercana.\n",
    "    *   Número de cápsulas restantes.\n",
    "    *   Estado de las cápsulas.\n",
    "    *   Si el estado actual es una victoria o una derrota."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a78a300",
   "metadata": {},
   "source": [
    "## **2. TABLA DE TRANSPOSICION**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a5438d",
   "metadata": {},
   "source": [
    "A pesar de las ventajas que la búsqueda Alpha-Beta presenta, es posible optimizar aún más el tiempo que esta transcurre así como el número de nodos que se visitan. Una técnica clásica muy utiliazada en esta situación son las Tablas de Transposición. Durante la búsqueda es bastante común, especialmente con árboles con un alto factor de ramificación, que se llegue a una posición que se ha evaluado anteriormente mediante sequencias de acciones distintas. Dichos estados se conocen como transposiciones y obviamente, dichas situaciones son desfavorables ya que estamos gastando tiempo en cálculos que ya hemos realizado previamente, y es por esto que existen las tablas de transposiciones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5127a3",
   "metadata": {},
   "source": [
    "En esencia, una tabla de transposición es un mapa que almacena posiciones y las asocia con la evaluación que se obtuvo en dicha posición. Sin embargo, hay varios puntos importantes a considerar sobre como se guardan las evaluaciones y como se recuperan:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041b3195",
   "metadata": {},
   "source": [
    "### **2.1. Tipos de nodos**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a215d280",
   "metadata": {},
   "source": [
    "Desde los comienzos de Alpha-Beta, se notaron las diferencias entre los nodos que se evalúan durante la búsqueda. Donald Knuth y Ronald Moore fueron los primeros en nombrar estos nodos (Knuth Type 1, Knuth Type 2, Knuth Type 3). Mediante los análisis de varios otros investigadores como Judea Pearl, Tony Marsland y Fred Popowich, se les cambió a denominar *PV-Nodes*, *Cut-Nodes* y *All-Nodes*. Estos tipos de nodos determinan el significado de la evaluación guardada en la tabla, por lo que se explicará el significado de cada uno:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97958fbb",
   "metadata": {},
   "source": [
    "<u>***PV-Nodes***</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6934aece",
   "metadata": {},
   "source": [
    "Los nodos de este tipo tienen como característica que la evaluación *s* obtenida por un nodo cae entre $\\alpha$ y $\\beta$, de manera que es el resultado exacto de realizar la búsqueda en esa rama. Además, dado esta característica, es el mismo mejor resultado que se obtendría de haber realizado una búsqueda minimax completa. Debido a lo mencionado, podemos decir que el valor de la evaluación obtenido es exacto y no un cota superior o inferior de su valor real.\n",
    "\n",
    "Como información adicional, el nombre *PV-node* viene de una variación de la búsqueda Alpha-Beta conocida como **Principal Variation Search** (*PV Search*), donde los únicos nodos que se tratan de expandir son aquellos con el mismo nombre. En nuestro caso no implementamos esta optimización, sin embargo sería un esfuerzo interesante estudiarlo en el futuro."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05538130",
   "metadata": {},
   "source": [
    "<u>***Cut-Nodes***</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705a5ec5",
   "metadata": {},
   "source": [
    "Estos nodos se dan cuando la evaluación obtenida ***s*** es mayor que $\\beta$, por lo que se produce un *beta-cutoff*. Esto quiere decir que ***s*** es **tan buena** que el oponente va a evitar que realicemos ese movimiento. Debido a esto, no tiene sentido continuar con la búsqueda en de los hijos de este nodo, por lo que se corta la rama y se abandona, dando el nombre a este tipo de nodo.\n",
    "\n",
    "Dado que no hemos evaluado todos los nodos hijos, no sabemos la evaluación exacta ***S*** del nodo padre, por lo que no podemos decir con certeza que la evaluación obtenida hasta ahora ***s*** es la resultante de haber realizado minimax. Debido ha esto, tenemos que la evaluación ***s*** es una cota de ***S***. Particularmente, como no conocemos todas las evaluaciones, decimos que es la **cota inferior** de ***S***, ya que esta debe ser al menos tan buena como $\\beta$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6ad221",
   "metadata": {},
   "source": [
    "<u>***All-Nodes***</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c889d27",
   "metadata": {},
   "source": [
    "Este tipo de nodos ocurren cuando se han explorado todos los hijos de un nodo particular y la mejor evaluación ***s*** es menor o igual que $\\alpha$. Esto significa que ***s*** es peor o igual a la mejor evaluación actual, por lo que ninguna de las acciones exploradas es deseable en comparación con otras ya exploradas anteriormente. Debido a esto, podemos decir que ***s*** es la **cota superior** de la mejor evaluación dada por $\\alpha$, ya que sabemos que la mejor evaluación es menor o igual a este valor.\n",
    "\n",
    "Como nota adicional, este tipo de nodos son aquellos que más ralentizan el proceso de búsqueda dentro de Alpha-Beta. Dado que se deben explorar todos los hijos para determinar si alguna evaluación es mayor que $\\alpha$, pero ninguno resulta serlo, este tipo de nodos representan un gran coste computacional. Es por eso que hay técnicas que ordenan los movimiento antes de extender la búsqueda de manera que los mejores movimientos se visiten primero. Técnicas como **Heuristic Move Ordering** o **Iterative Deepening** permiten encontrar mejores movimientos antes en la búsqueda, lo que permite saltarse más nodos de este tipo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b43e1dd",
   "metadata": {},
   "source": [
    "### **2.2. Método de almacenamiento**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2010a3de",
   "metadata": {},
   "source": [
    "Con lo expuesto, somos capaces de categorizar nodos de forma acorde a su evaluación. Sin embargo, aún no hemos discutido de que manera codificamos un estado particular, por lo que a continuación exponemos como lo hacemos y los problemas con los que nos encontramos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa088da9",
   "metadata": {},
   "source": [
    "Como se discutió previamente, las tablas de transposición asocian estados de la partida a evaluaciones y otra información útil. Esta asociación normalmente viene dada por un mapa (o diccionario en Python), donde se especifícan las llaves como la codificación de las partidas y los valores como las evaluaciones de estas. El método de codificación, sin embargo, difiere entre aplicaciones debido a la naturaleza de los estados mismos.\n",
    "\n",
    "Por ejemplo, en ajedrez, dos métodos comunes para codificar el estado de un tablero son **Zobrist Hashing** y **BCH Hashing** (*Bose-Chaudhuri-Hocquenghem*). Estos métodos incluyen técnicas muy por encima de lo necesario para este proyecto, y más relevante, muy particulares para el juego del ajedrez. Implementar las técnicas que usan no es *imposible*, pero sería una tarea que habría tomado más tiempo del presente para esta práctica.\n",
    "\n",
    "En su lugar, el código proporcionado por *UC Berkeley* hace uso de la función estándar *hash* de Python. Mediante esta función, se codifica toda la información posible sobre un estado en un solo número, de manera que podemos utilizarla para almancenar los estados del juego en la tabla de transposición."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57219e79",
   "metadata": {},
   "source": [
    "<div align=center>\n",
    "    <img src=\"../fotos/transposition_hash.png\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99a6d36",
   "metadata": {},
   "source": [
    "El código mostrado es el método mencionado anteriormente. Como se puede observar, hace uso de la información de la que se compone un estado de la partida, como los estados de pacman y los fantasmas, la comida, lás cápsulas y la puntuación actual. Sin embargo, este código incluye un problema muy grave, este siendo el módulo que se encuentra al final.\n",
    "\n",
    "Después de extensiva búsqueda, encontramos que no hay razón aparente para la que exista este módulo. Ni en el [repositorio original](https://github.com/karlapalem/UC-Berkeley-AI-Pacman-Project) ni en la [página del projecto](https://inst.eecs.berkeley.edu/~cs188/fa24/projects/) encontramos referencia a esta decisión. Y no es sin razón que encontramos que es una decisión errónea:\n",
    "\n",
    "1. El módulo limita el número de estados posibles a $1048575$, sin embargo esto no depende del tamaño del mapa\n",
    "2. Estados diferentes son capaces de acabar con el mismo hash debido al efecto del módulo\n",
    "3. Es posible (aunque raro) que las operaciones matemáticas resulten en el mismo hash, debido a que no se ha tenido cuidado en como se han realizado\n",
    "\n",
    "En la práctica, encontramos que el uso de la tabla de transpoción resultaba en distintas partidas, cuando su uso no debería afectar a los resultados que la búsqueda Alpha-Beta habría obtenido. Tras un análisis riguroso de los hashes usados y las situaciones precisas en las que las diferencias se originaban, encontramos que el módulo causaba que estados con hashes distintos resultaran en la misma codificación."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce8d7d1",
   "metadata": {},
   "source": [
    "Este problema está relacionado con uno mucho más amplio, conocido como *Hash Collision*. Este problema surge por el hecho de que los hashes intentan comprimir un número infinito de elementos dentro de un conjunto finito de codificaciones. Debido a esto, no es posible que un objeto o elemento particular tenga un hash totalmente único, sin embargo, es gracias al gran ingenio de los desarrolladores de estos hashes que se previene que este problema ocurra frequentemente, aunque nunca sea posible evitarlos del todo.\n",
    "\n",
    "En comparación, el hash dado por el código original restringe el número de estados sin explición alguna, y es evidente que hay mapas que poseen más de los estados mencionados. Debido a esto, encontrabamos que algunos estados obtenían las evaluaciones de estados diferentes, lo cual es un gra problema para una técnica como la tabla de transposición. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc855cf",
   "metadata": {},
   "source": [
    "Para solucionar estos problemas, optamos por una técnica ligeramente distinta de guardar la información de un estado, que se puede observar en la siguiente imagen. Aquí, dejamos de lado el módulo anterior y usamos los resultados de los hashes en sí mismos. Dado que los números generados por estos son enormes (fácilmente en los trillones), es mucho menos común que hayan colisiones, aunque las operaciones aritméticas intermedias que realizamos aumentan esta probabilidad ligeramente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a9bfa3",
   "metadata": {},
   "source": [
    "<div align=center>\n",
    "    <img src=\"../fotos/transposition_new_hash.png\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9919755d",
   "metadata": {},
   "source": [
    "Gracias a esto, encontramos que no se producen colisiones y los juegos dados por Alpha-Beta son idénticos a aquellos dados por la Tabla de Transposición bajo las mismas situaciones. En nuestras pruebas, no hemos detectado ningún caso en el que ambos den lugar a juegos distintos aunque probásemos cientos de juegos, por lo que podemos concluir que este método de codificación es lo suficientemente robusto."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb371fd",
   "metadata": {},
   "source": [
    "### **2.3. Lectura**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd149022",
   "metadata": {},
   "source": [
    "<div align=center>\n",
    "    <img src=\"../fotos/transposition_lookup.png\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89d5eac",
   "metadata": {},
   "source": [
    "Para leer de la Tabla de Transposición, le proporcionamos la codificación del estado al cual queremos acceder, la profundidad de la búsqueda actual y los valores de $\\alpha$ y $\\beta$. En primer lugar, es posible que el estado actual no se haya visitado anteriormente, por lo que el estado no se encontrará en la tabla e informaremos de que ha ocurrido un error buscando el estado.\n",
    "\n",
    "De no ser así, obtendremos el objeto entrada descrito posteriormente, que almacena toda la información importante sobre el estado actual. Sin embargo, no podemos hacer uso de dicha información incondicionalmente, algunas condiciones deben cumplirse. Primeramente, solo haremos uso de la evaluación almacenada si la profundidad a la que se encontró dicha evaluación es al menos tan profunda como la del estado anterior, sino más. Esto se debe a que queremos hacer uso de aquellas evaluaciones que hayan considerado más nodos en su búsqueda, ya que estas incluirán mayor cantidad de información sobre las posibles respuestas del oponente.\n",
    "\n",
    "En segundo lugar, debemos considerar el tipo de evaluación que se dió cuando se guardó esta anteriormente. El hecho de que se haya dado el mismo estado en un momento previo de la búsqueda no implica que su tipo de evaluación sea el mismo, por lo que debemos concretar si se dan las mismas condiciones antes de hacer uso de la evaluación. Como se observa en la imágen, las comprobaciones que se realizan son las mismas que se usan para determinar el tipo de evaluación, por lo que solo si las condiciones del estado actual son las mismas que se dieron cuando se almacenó anteriormente haremos uso de lo guardado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf18235",
   "metadata": {},
   "source": [
    "<div align=center>\n",
    "    <img src=\"../fotos/transposition_entry.png\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d655b1",
   "metadata": {},
   "source": [
    "## **3. FUNCIÓN DE EVALUACIÓN**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48ff337",
   "metadata": {},
   "source": [
    "Una vez expuestas las metodologías empleadas en términos de ejercer la búsqueda, cabe señalar cuál es la función de evaluación en base a que estas últimas se nutren y apoyan. De manera concreta, a lo largo de esta sección se explorarán los siguientes apartados componentes:\n",
    "\n",
    "<ol>\n",
    "    <li>\n",
    "        <strong>Introducción sobre los parámetros</strong>\n",
    "    </li>\n",
    "    <li>\n",
    "        <strong>Explicación de las secciones</strong>\n",
    "    </li>\n",
    "    <li>\n",
    "        <strong>La salida</strong>\n",
    "    </li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e87e3b",
   "metadata": {},
   "source": [
    "### **3.1 Introducción sobre los parámetros**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6417316a",
   "metadata": {},
   "source": [
    "Con relación a los parámetros de que nuestra función de evaluación se compone, podemos encontrar los que siguen:\n",
    "\n",
    "**1.list_of_moves** **$\\rightarrow$ list[str]**\n",
    "\n",
    "Se expone como una lista componente en los últimos cuatro movimientos que Pacman ha desarrollado y que estarán codificados en términos de cadenas de texto en representación de los puntos cardinales. Con objeto de justificar su existencia de forma escuesta, encontramos que esta remite a la necesidad de escape frente a un bucle de movimientos que de manera posterior se explicará.<br><br>\n",
    "\n",
    "\n",
    "**2.ghost_heat_map** **$\\rightarrow$ dict[tuple[int,...], np.ndarray]**\n",
    "\n",
    "Es un diccionario cuyas llaves codificarán las distintas posiciones que puede ocupar el fantasma y los valores denotarán el espectro de influencia que los enemigos pueden tener ante el layout que se ha seleccionado en la inicialización del agente con esa configuración posicional concreta. <br><br>\n",
    "\n",
    "**3.current_heat_map** **$\\rightarrow$ np.ndarray**\n",
    "\n",
    "Es un array dispuesto para la evaluación de la peligrosidad estática de las celdas libres asociadas al mapa que hemos escogido en la llamada al Agente. De esta manera pues, localizamos que junto con el parámetro anterior lo que modelaremos será una métrica dinámica en representación de la peligrosidad relativa de las distintas posiciones que Pacman va adoptando.<br><br>\n",
    "\n",
    "\n",
    "**4.original_food** **$\\rightarrow$ list[int]**\n",
    "\n",
    "Es un array en representación del número de capsulas de comida de que cada una de las particiones del mapa es componente; división espacial la cual se presentará más adelante. No obstante, cabe señalar que la aplicabilidad directa de este atributo ha sido derogada en base a una serie de razones inherentes al descarte del cálculo de las fuerzas que veremos posteriormente.<br><br>\n",
    "\n",
    "\n",
    "**5.state** **$\\rightarrow$ GameState**\n",
    "\n",
    "Es una representación del estado actual del juego que nos permitirá el acceso a parámetros utilitarios tales como la posición de Pacman o la de los fantasmas,  e incluso valores como la puntuación y distribución global de la comida  para el ply con que trabajamos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeaf711e",
   "metadata": {},
   "source": [
    "<div align = center>\n",
    "    <img src = '../fotos/eval_function_init.png'>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d426a580",
   "metadata": {},
   "source": [
    "### **3.2 Explicación de las secciones**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6342364",
   "metadata": {},
   "source": [
    "Tal y como habíamos dejado entreveer anteriormente, existen una serie de secciones en base a las cuales se construirá el cálculo final de nuestra función encargada de ejercer una evaluación sobre el estado actual.\n",
    "\n",
    "Cabe señalar, no obstante, que se omitirá la parte del código referente a la obtención de las posiciones de los fantasmas y de Pacman en tanto que de manera explícita ya ha sido mencionado el cómo de su obtención anteriormente.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be335e1",
   "metadata": {},
   "source": [
    "#### ·<u>***SECURITY***</u>\n",
    "\n",
    "En esta sección lo que se buscará es calcular la distribución de peligrosidad en el mapa bajo el que trabajamos de tal forma que cada una de las casillas libres quede ponderada de base por un determinado factor de peligrosidad. \n",
    "\n",
    "Distinguimos dos partes claras en el proceso:<BR><br>\n",
    "\n",
    "\n",
    "**MAPA TOPOLÓGICO ESTÁTICO**</u>\n",
    "\n",
    "De cara a lograr todo esto, encontramos que en primer lugar se generó un mapa de calor en representación del riesgo estático que a cada una  de las distintas zonas del grid se asociaba.\n",
    "\n",
    "En lo que refiere a la construcción de dicha estructura, de manera particular se atribuyó un valor de peligrosidad $k \\in \\left\\{0,5\\right\\}$ a cada una de las celdas y que vino dado en base a un criterio que inequívocamente se había de apoyar sobre la información topológica. \n",
    "\n",
    "Con objeto de explicar cuál ha sido este criterio espacial, localizamos que ha tenido su fundamento en el número de opciones posibles de movimiento con que Pacman contaba en cada momento. Consecuentemente, encontramos que las intersecciones entre caminos se presentarán como las zonas más seguras topológicamente, mientras que a medida que nos vamos acercando a las esquinas, dicho valor de seguridad va decrementado hasta que estas últimas son alcanzadas.\n",
    "\n",
    "No obstante, también cabe señalar cuál es el modelo de evolución de la puntuación. En primer lugar, encontramos que, tal y como hemos mencionado, a las intersecciones se les atribuirá una puntuación de peligrosidad 0 que irá incrementando a medida que nos acerquemos a los extremos del mapa. Dicha ponderación crecerá hasta un valor que vendrá condicionado por la longitud del recorrido actual hasta las esquinas y que habrá de estar en concordancia con el flujo de puntuación que llega por parte de las otras vía de  comunicación. \n",
    "\n",
    "Si bien puede resultar confuso, veamos el siguiente ejemplo:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd25a4d5",
   "metadata": {},
   "source": [
    "<div align = center>\n",
    "    <img src = '../fotos/eval_mapa_calor.png'>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ffe87b",
   "metadata": {},
   "source": [
    "Como podemos observar, el valor mínimo irá progresando y creciendo en base a la metodología que anteriormente hemos descrito. No obstante, y entendiendo el mapa como un sistema recorrido por un fluido, si tenemos dos fuentes generadoras del mismo, llegará un punto en que ambas se encuentren y tengan que igualar fuerzas. Cabe señalar a su vez que el avance por cada una de las distintas fuentes (círculos blancos) se  produce a la misma velocidad y en todas las direcciones que los movimientos legales de Pacman permitan en cada momento. \n",
    "\n",
    "En esencia, lo que se pretendía recalcar con esta aclaración es el hecho de que por cuestiones de simetría los valores mínimos de seguridad que dentro del dominio definido se encuadran no siempre van a ser alcanzables en las esquinas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799552f2",
   "metadata": {},
   "source": [
    "**COMPONENTE DINÁMICA**\n",
    "\n",
    "Expresado lo anterior, y dado que pretendíamos ejercer una evaluación global del peligro, se expuso como necesario el considerar el impacto que la presencia de los enemigos o fantasmas podría llegar a tener sobre la metodología de puntuación que en el primer apartado se ha establecido. \n",
    "\n",
    "Con ello, entenderemos al tipo fantasma como un campo con algún tipo de energía dispuesta y que,  a  medida que se va desplazando sobre las casillas ponderadas en base a la topología, va alterando su valor. Al igual que sucede en campos definidos en términos formales, el impacto o potencia del mismo irá variando a medida que nos vayamos alejando del foco emisor. Si bien campos como el eléctrico tienen un potencial que es cero en el infinito, lo que pretendíamos modelar era más el efecto de sumidero de peligrosidad  que el ceñirnos a lo que sería correcto desde un punto de vista teórico. \n",
    "\n",
    "Consecuentemente, encontramos que generaremos un modelado de rango de influencia limitado $r$, centrado en el fanstasma y cuyo valor variará en voluntad de adaptarse a la geometría y dimensiones de cada uno de los mapas dispuestos. Veamos pues una pareja de ejemplos de lo que el efecto de dicho fantasma supone en elecciones de grid distintas en una misma posición:<br><br>\n",
    "\n",
    "\n",
    "<center><strong>1.MAPA MEDIUM CLASSIC</strong></center>\n",
    "\n",
    "<center><strong>2.MAPA TRICKY CLASSIC</strong></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406b85d9",
   "metadata": {},
   "source": [
    "<div align = center>\n",
    "    <img src ='../fotos/eval_ghosts_pos.png'>\n",
    "\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36de554",
   "metadata": {},
   "source": [
    "Tal y como podemos observar, el rango de influencia o de impacto entre ambos mapas se expone como distinto del mismo modo que también lo son sus dimensiones; siendo  estas más elevadas en el mapa que presenta un mayor tamaño."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc968cde",
   "metadata": {},
   "source": [
    "Finalmente, y en voluntad de exponer cómo dicho campo actúa sobre la evaluación estática antes ejercida, entendemos que simplemente se presentará como una combinación lineal de valores, esto es, una suma de los arrays representados en ambas metodologías de ponderación.\n",
    "\n",
    "Sea pues esta la fórmula que codifica el valor de cada una de las celdas finales:<br><br>\n",
    "\n",
    "$$\\text{Final danger} = \\text{Static Danger + Dynamic Danger}$$\n",
    "\n",
    "\n",
    "\n",
    "Veamos a continuación un ejemplo de dicho impacto combinado para un fantasma centrado en la posición $(2,1)$ y bajo la elección del mapa $\\text{Medium Classic}$. No obstante, antes de proseguir cabe señalar que el origen de coordenadas se encuentra en la esquina superior izquierda del grid:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ddb453",
   "metadata": {},
   "source": [
    "<div align = center>\n",
    "    <img src ='../fotos/eval_dynamic_vs_static.png'>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e58535",
   "metadata": {},
   "source": [
    "Como podemos observar, en la posición de centrado en el mapa izquierdo ha incrementado la peligrosidad como producto del impacto generado por parte de la presencia del fantasma; así como también lo ha hecho en las zonas que dentro de su rango de influencia se encuentran. Cabe matizar a su vez que la distribución de colores varía al atender a un nuevo máximo como producto de la introducción del dinamismo a la evaluación."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d51e7ef",
   "metadata": {},
   "source": [
    "**CÓDIGO**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b57dd2",
   "metadata": {},
   "source": [
    "Finalmente, cabe señalar que los diccionarios que codifican los distintos mapas de calor estáticos y dinámicos estarán almacenados en un formato pickle para facilitar su carga desde el agente y su inyección como parámetro a la función de evaluación.\n",
    "\n",
    "Matizado esto último, veamos una imagen asociada al código que ha sido empleado para desempeñar la tarea presentada en líneas anteriores:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e4468b",
   "metadata": {},
   "source": [
    "\n",
    "<div align = center>\n",
    "    <img src ='../fotos/eval_security.png'>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912bf291",
   "metadata": {},
   "source": [
    "#### ·<u>***MEAN-DANGER-CURRENT-QUADRANT***</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6551be8",
   "metadata": {},
   "source": [
    "A lo largo de esta sección lo que se buscará es el determinar la peligrosidad media de la comida presente en la división del mapa dentro de la cual Pacman se encuentra en el ply actual. \n",
    "\n",
    "Con ello, localizamos que los apartados construidos de cara a ejercer dicha labor son los que siguen:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3031995",
   "metadata": {},
   "source": [
    "**DIVIDIENDO EL ESPACIO**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a587a4",
   "metadata": {},
   "source": [
    "Tal y como mencionábamos en la sección referente a la presentación de los parámetros, el mapa sufrirá una división en cuatro secciones o cuadrantes que atenderán a una partición esquitativa del espacio fundamentada bajo el trabajo con las dimensiones del layout. \n",
    "\n",
    "Si tomamos por ejemplo un $Layout = (x,y)$, entonces los valores en base a los cuales se van a segregar los cuadrantes serán los que siguen:\n",
    "\n",
    "$$h = \\lceil\\frac{x}{2} \\rceil $$\n",
    "$$w = \\lceil\\frac{y}{2} \\rceil $$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a490d15e",
   "metadata": {},
   "source": [
    "<div align = center>\n",
    "    <table>\n",
    "        <tr align=center>\n",
    "            <td align=center> <strong>CUADRANTE<strong></td>\n",
    "            <td> <strong>CONDICIÓN X<strong></td>\n",
    "            <td> <strong>CONDICIÓN Y<strong></td>\n",
    "        </tr>\n",
    "        <tr align=center>\n",
    "            <td> 1</td>\n",
    "            <td> x less than h </td>\n",
    "            <td> y less than w </td>\n",
    "        </tr>\n",
    "        <tr align=center>\n",
    "            <td> 2</td>\n",
    "            <td> x more equal than h </td>\n",
    "            <td> y less than w </td>\n",
    "        </tr>\n",
    "        <tr align=center>\n",
    "            <td> 3</td>\n",
    "            <td> x more equal than h </td>\n",
    "            <td> y more equal than w </td>\n",
    "        </tr>\n",
    "        <tr align=center>\n",
    "            <td> 4</td>\n",
    "            <td> x less than h </td>\n",
    "            <td> y more equal than w </td>\n",
    "        </tr>\n",
    "    </table>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf4c4ec",
   "metadata": {},
   "source": [
    "Una imagen asociada a dicha división en cuadrantes representada sobre el mapa mediumClassic sería la que sigue:\n",
    "\n",
    "<div align = center>\n",
    "    <img src ='../fotos/eval_quadrants.png'>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58dee7b9",
   "metadata": {},
   "source": [
    "**¿EN QUÉ CUADRANTE ESTÁ PACMAN?**\n",
    "\n",
    "\n",
    "Construida dicha partición, habremos de determinar cuál es el cuadrante concreto en que se encuentra Pacman en voluntad de poder ejercer el cálculo sobre la media de peligrosidad de las celdas de comida que localmente lo rodean. \n",
    "\n",
    "La justificación de la elección del cuadrante actual para este cálculo es que la función de evaluación adquiere un carácter estático y confiamos en la capacidad de la búsqueda para encontrar evaluaciones de Pacman en otros cuadrantes a medida que esta progresa.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35653f80",
   "metadata": {},
   "source": [
    "**MEDIA DE LA PELIGROSIDAD DE LA COMIDA DEL CUADRANTE**\n",
    "\n",
    "Simplemente se construirá como el sumatorio del riesgo dinámico asociado a cada una de las celdas con comida del cuadrante en que Pacman se encuentra actualmente partido por el total de este tipo de celdas. Sea por ejemplo el cuadrante $1$ con un total de $16$ celdas no vacías y un sumatorio de peligrosidad construido de la siguiente manera:\n",
    "\n",
    "$$n_{celdas} = 16$$\n",
    "$$danger = \\sum_{i = 1}^{n_{celdas}}\\text{mapa de peligrosidad}\\ [i]$$\n",
    "\n",
    "$$\\text{Mean of danger}\\ (\\mu) = \\frac{danger}{n_{celdas}}$$\n",
    "\n",
    "\n",
    "Cabe señalar que el mapa de peligrosidad codifica la combinación del riesgo estático y dinámico que de manera anterior hemos expuesto.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31c971f",
   "metadata": {},
   "source": [
    "**CONCLUSIÓN Y VÍNCULO**\n",
    "\n",
    "En conclusión, esta métrica nos permitirá aplicar la concepción de seguridad desarrollada en el apartado anterior, a la par que obtener un estimador insesgado como es el de la media muestral para ponderar cómo de bueno es el cuadrante que actualmente ocupo en términos de la comida que en el mismo se encuadra. \n",
    "\n",
    "Valores muy elevados de peligrosidad media establecerán una alta voluntad de transición  hacia otros cuadrantes, mientras que términos más reducidos computarán el que se entienda el estado actual como uno no desfavorable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beabe778",
   "metadata": {},
   "source": [
    "#### ·<u>***LOOKING FOR DENSITY***</u>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42df46b",
   "metadata": {},
   "source": [
    "Tal y como habíamos mencionado anteriormente, la consideración que ejerce la función de evaluación se desarrolla desde un punto de vista estático y por ende se tomará con respecto al cuadrante en que actualmente Pacman se encuentra.\n",
    "\n",
    "Si bien antes hemos considerado la peligrosidad asociada a la distribución de la  comida en la región donde nos hayamos, otro de los factores relevantes del juego se presenta como la cantidad de la misma que somos capaces de comer en el menor tiempo posible. De ahí pues que surja la  necesidad de ponderar cuál es el punto caliente donde esta última está concentrada. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f8b6cc",
   "metadata": {},
   "source": [
    "**CENTROIDE**\n",
    "\n",
    "Hilando lo descrito anteriormente, la categorización de la bondad de una posición dentro del cuadrante será, además de mi seguridad como jugador, la cercanía respecto a una mayor cantidad de cápsulas o de comida. \n",
    "\n",
    "Puesto que necesitábamos como tal considerar el impacto de la totalidad de las cápsulas sobre la posición actual, se decidió tomar una medida o equivalencia de la influencia que todas estas tienen en conjunto. Con ello, decidimos que el cálculo del centroide de la distribución de las cápsulas se presentaba como idóneo puesto que nos permitía considerar un punto caliente único que era media de la posición de todas las cápsulas pertenecientes a la división actual.\n",
    "\n",
    "Sea pues la siguiente fórmula empleada para su cálculo y asumiendo la disposición de un set de comida  $S \\left\\{(x,y), \\forall x,y \\in \\N ^+ \\right\\}$ en el cuadrante actual:\n",
    "\n",
    "$$\\text{Centroid}\\ (x_c, y_c) = \\frac{\\sum_{i = 1}^{|S|} S_i}{|N|} \\in \\N^+$$\n",
    "\n",
    "De esta manera, disponemos de una heurística o guía que nos permite dictaminar de forma dinámica cuál es ese punto en el cual tengo más posibilidades de alcanzar una mayor cantidad de cápsulas. Dicha atribución del adjetivo \"dinámico\" radica en que se irá actualizando a medida que vayamos consumiendo y por ende desplazándose hacia las zonas de mayor densidad o interés.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7a5de0",
   "metadata": {},
   "source": [
    "<div align = center>\n",
    "    <img src ='../fotos/eval_centroid.jpg'>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7326a67d",
   "metadata": {},
   "source": [
    "**DISTANCIA DE MANHATTAN**\n",
    "\n",
    "Una vez obtenido dicho valor, se computará el desplazamiento horizontal y vertical ideal respecto al centroide calculado de manera previa, esto es, la Distancia de Manhattan. Con ello, lo que pretenderemos penalizar es el estar alejados de ese punto caliente que sobre la distribución de comida se ha generado.\n",
    "\n",
    "$$Manhattan(a,b) = |a_x - b_x| + |a_y - b_y|$$\n",
    "Cabe señalar a su vez que en el cálculo de dicha distancia no se ha tenido en consideración la existencia de obstáculos físicos de ningún tipo y por ende la métrica obtenida es un ideal que se aleja de la realidad en ese aspecto. \n",
    "\n",
    "En el caso de la imagen anterior por ejemplo, la distancia de Manhattan respecto al centroide se presentaría como de $2$; penalización la cual se expondría como muy reducida dada la proximidad al foco de comida de la partición."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ea3082",
   "metadata": {},
   "source": [
    "#### ·<u>***REPEATING MOVES***</u>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0925b054",
   "metadata": {},
   "source": [
    "La existencia de esta sección surge en la materia que Pacman cae en ciertas ocasiones en un bucle de movimientos del tipo **north-south** o **west-east** que repite hasta que un fantasma se encuentra lo suficientemente cerca como para romperlo.\n",
    "\n",
    "Las causas exactas de este fenómeno no son claras ni definidas, pero tenemos las siguientes hipótesis:\n",
    "\n",
    "\n",
    "1. El centroide cae en lugares centrales del cuadrante al estar distribuida la comida por los extremos del mismo y por ende Pacman queda atrapado en dicha posición.\n",
    "\n",
    "2. Si queda poca o ninguna comida en el cuadrante y Pacman está alejado de otras particiones, la búsqueda no tiene la suficiente profundidad como para determinar el estado del jugador en los cuadrantes distantes. Consecuentemente, no le queda otra opción más que moverse de forma incoherente o  repetir movimientos en bucle. \n",
    "\n",
    "\n",
    "\n",
    "**SOLUCIÓN**\n",
    "\n",
    "Con voluntad de paliar esto último, y tal y como mencionábamos en la inicialización, hemos atribuido al hecho de que se repitan secuencias de movimientos una penalización de tal forma que se descarten las ramas en que estos últimos se producen.\n",
    "\n",
    "No obstante, hay que tener cuidado con este tipo de castigo. La razón fundamental para la exigencia de prudencia es que, de ser muy severa la penalización, Pacman considerará como una opción menos mala el ser comido por un fantasma y por ende finalizar el juego. Si bien todo este razonamiento era la idea inicial, la aplicación práctica no ha terminado de ser fructífera en el aspecto para el cual fue creada. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9a53be",
   "metadata": {},
   "source": [
    "<div align = center>\n",
    "    <img src ='../fotos/eval_repeating_movs.png'>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd357bd",
   "metadata": {},
   "source": [
    "#### ·<u>***REWARDING FOOD***</u>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc367cc3",
   "metadata": {},
   "source": [
    "Con voluntad de incidir más profundamente sobre una idea que de manera implícita hemos estado desarrollando, diríamos que el  juego de Pacman en esencia se presenta como un equilibrio. Es la búsqueda de un balance constante entre ingerir toda la comida presente y aguantar lo máximo posible con vida en la partida, teniendo la victoria como objetivo último.\n",
    "\n",
    "En lo que respecta al segundo de los aspectos, y gracias a las funciones desarrolladas en términos de la evaluación de la peligrosidad, estamos bien cubiertos. No obstante, necesitamos de un catalizador en lo que el consumo de comida refiere y que no se limite únicamente a la acción atractora del centroide del cuadrante concreto que antes habíamos presentado, sino al ejercicio de medidas más directas. De ahí surge pues el desarrollo de esta sección.\n",
    "\n",
    "\n",
    "**LA IDEA**\n",
    "\n",
    "El concepto bajo el que este fragmento de la función de evaluación se define es muy concreto y directo: si estás cerca de cápsulas de comida, eventualmente las acabarás alcanzando y por ende tu posición se evaluará como positiva en una cierta medida que de manera empírica se ha ajustado.\n",
    "\n",
    "No obstante, y a modo de contrapunto, también se evaluará de manera negativa la cantidad de comida que en el mapa resta para alentar a Pacman a que no pare de comer hasta que dicho decremento de puntuación sea reducido.\n",
    "\n",
    "Expuesto lo anterior, entendemos que este fragmento será el que, de manera  complementaria a **Looking for density**, permita el que se premie no solo estar en un área donde la densidad de comida sea elevada, sino que también se dé mérito al que yo, como jugador, esté cerca de ella y  me la acabe comiendo. \n",
    "\n",
    "En esencia, la función **Looking for density** es un indicador acerca de  hacia dónde nos debemos dirigir en el mapa y el fragmento asociado a **Rewarding Food** es el que, dentro de esa zona a que hemos sido guiados, nos incita a comer las cápsulas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd5eb87",
   "metadata": {},
   "source": [
    "<div align = center>\n",
    "    <img src ='../fotos/eval_rewarding_food.png'>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e94f305",
   "metadata": {},
   "source": [
    "<!-- <div align = center>\n",
    "    <img src ='../fotos/eval_rewarding_food.png'>\n",
    "\n",
    "</div> -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86fe7081",
   "metadata": {},
   "source": [
    "#### ·<u>***LAS FUERZAS***</u>\n",
    "\n",
    "Si bien el modelado de fuerzas es una idea que finalmente ha sido descartada, se presta como interesante al menos mencionarla. \n",
    "\n",
    "Dada la consideración de los centroides que a los distintos cuadrantes se atribuyen como sumideros o atractores, resulta coherente el que todos ellos tiren  de Pacman con una cierta fuerza. Será la resultante de todas ellas la que actúe como una guía de la dirección o cuadrante concreto hacia el cual nos tenemos que desplazar.\n",
    "\n",
    "En términos de expresar esto último, se tomó la $\\text{Ley de Gravitación Universal}$ en ausencia de la constante de Gravitación Universal y con algunas modificaciones:\n",
    "\n",
    "$$F = \\frac{\\text{Densidad comida}^{-1}}{\\text{Distancia Centroide}^2}$$\n",
    "\n",
    "Tal y como podemos observar, en lugar de ponderar el producto de las masas en el numerador, consideramos a Pacman como una masa unitaria y lo escalamos por la inversa de la densidad de comida en el cuadrante sobre el cual se está calculando la fuerza. De esta manera, lo que estamos primando es que el jugador finalize con la comida en el cuadrante presente antes de que la partición más cercana y distinta de la actual tire hacia él con una mayor intensidad.\n",
    "\n",
    "Si bien resultaba una idea interesante, han sido las dificultades de modelar algo con estricta coherencia en el numerador las que han conllevado inevitablemente a su descarte. <br><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ad61a9",
   "metadata": {},
   "source": [
    "### **3.3 La salida**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fbc8881",
   "metadata": {},
   "source": [
    "Una vez hemos desarrollado cada uno de los términos componentes de la función de evaluación, cabe expresar cómo se calculará la salida o valor de retorno de la misma. Atendamos pues a la siguiente fotografía:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f11fa3",
   "metadata": {},
   "source": [
    "<div align = center>\n",
    "    <img src ='../fotos/eval_output.png'>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf03305",
   "metadata": {},
   "source": [
    "Tal y como podemos observar, encontramos una correlación entre los apartados componentes descritos y las variables de salida:\n",
    "\n",
    "\n",
    "**1.Score**\n",
    "\n",
    "Se corresponde con el valor de la puntuación que de manera interna el juego genera para nuestro estado actual. Es una métrica que por nuestra parte no es modificable.<br><br>\n",
    "\n",
    "\n",
    "\n",
    "**2.Manhattan_to_pacman_centroid**\n",
    "\n",
    "Se corresponde con el apartado **LOOK FOR DENSITY** y se encargará de penalizar linealmente la distancia existente respecto al centroide del cuadrante en que Pacman se encuentra. Con ello, encontramos que su valor será sustraído del de la puntuación global con una ponderación de uno. \n",
    "\n",
    "Si bien puede resultar arbitrario el escalado o valor  de dicho módulo, al representar  la Distancia de Manhattan ideal respecto al centroide, hemos considerado que empíricamente se tornaba  como adecuado o no excesivamente grande como para forzar comportamientos de manera brusca.<br><br>\n",
    "\n",
    "\n",
    "**3.Mean of danger**\n",
    "\n",
    "Atiende al apartado de **MEAN-DANGER-CURRENT-QUADRANT** y se encargará de penalizar con un factor de escalado de uno la peligrosidad media de las celdas con comida que el cuadrante actual componen. \n",
    "\n",
    "Dado que el riesgo asociado a las posiciones es un valor $V \\in [0,10]$ vía la acción de los fantasmas en el peor de los casos y con una geometría de mapa favorable, se torna como adecuado el sustraer dicha magnitud  linealmente al equipararse en el límite alcanzable con la recompensa que la ingesta de una unidad de comida trae consigo.\n",
    "\n",
    "Cabe señalar que dicho caso límite de sustracción se dará única y exclusivamente en situaciones donde solo reste una cápsula, que se encuentre en la posición más peligrosa del cuadrante y que el fantasma esté sobre ella. <br><br>\n",
    "\n",
    "\n",
    "\n",
    "**4 Pos_eval**\n",
    "\n",
    "Responde al apartado **SECURITY** y se tornará como el decremento del score del estado actual en la  magnitud  de pos_eval con un factor de escalado de $2$. Con ello, lo que pretenderemos modelar es el que Pacman evite o conciba como negativo el encontrarse en posiciones que pueden poner en riesgo la continuidad de la partida. \n",
    "\n",
    "Con objeto de justificar dicho factor de escalado, localizamos que lo que se pretenden impulsar es que si el fantasma está próximo o si la posición ya de por sí es lo suficientemente mala, no nos interesa el arriesgarnos a consumir dicho valor de comida. Por ejemplo, si contamos con una posición evaluada como $5$ en términos de peligrosidad, directamente se cancela la presencia de una comida; así como si el fantasma se encuentra próximo a Pacman, la situación se torna incluso como menos favorable.<br><br> \n",
    "\n",
    "\n",
    "\n",
    "**5. Devaluation**\n",
    "\n",
    "Este apartado actúa un poco como un cajón de sastre y aglutina tanto la penalización desarrollada por parte de la repetición de movimientos, como la relajación de esta última acontecida vía la función **Rewarding Food**. En términos de clarificar esto último, consideremos la siguiente fórmula\n",
    "\n",
    "$$A: \\text{aporte de penalización de movimientos}$$\n",
    "$$B: \\text{aporte de recompensa por comida}$$\n",
    "\n",
    "\n",
    "$$ \\text{devaluation} = A + B$$\n",
    "\n",
    "\n",
    "Dado que el módulo de devaluation es tomado en la función de forma negativa, lo que vamos a buscar en todo momento es maximizarlo, esto es, - minimizarlo o acercarlo lo máximo posible a 0. De esta manera, lo que se preconizará es que, dado un aporte  positivo por parte de A, lo suministrado por B sea lo más grande posible en términos de módulo pero con signo negativo. \n",
    "\n",
    "Con objeto de conseguir ese caso ideal en que lo sustraído en  la resultante se presenta como mínimo, se ha de satisfacer el que la proximidad a la comida se exponga como máxima y la cantidad restante de ella se denote como el mínimo modelable; factores los cuales son inherentes a la sección **REWARDING FOOD** determinada previamente.\n",
    "\n",
    "\n",
    "En esencia, lo que se busca con este valor fruto de una acción combinada es el suavizar el impacto que una situación poco usual puede tener en términos de puntuación y que por ende mayoritariamente representará el aporte resultante positivo de la bondad de una posición en base a los criterios expuestos de manera previa. \n",
    "\n",
    "Considerando pues el fenómeno de la repetición de movimientos como algo eventual, encontramos que los espectros en que se moverán los valores de este término modelado estarán acotados inferiormente por comida distante y la existencia de gran cantidad de ella y un valor máximo que responderá al hecho de que solo reste una cápsula y esta sea próxima a mí.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a98d0d",
   "metadata": {},
   "source": [
    "## **4. LA RED**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75d7e41",
   "metadata": {},
   "source": [
    "Parte de los requerimientos de la práctica especificaban la implementación de una red neuronal para sustituir la función de evaluación que hemos descrito previamente. Esta red debe coger el estado actual del juego y devolver un solo valor, siendo este la evaluación asociada el estado actual. Para poder realizar este requerimiento, primero tuvimos que encontrar la manera de obtener los datos con los cuales entrenar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd20dca9",
   "metadata": {},
   "source": [
    "### **4.1. Recolección de datos**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2afa78",
   "metadata": {},
   "source": [
    "Originalmente, los juegos se almacenan en la carpeta `pacman_data/` y los csv generados contienen solo información sobre el estado del mapa en cada posición, pero nosotros requirimos de información sobre la evaluación de cada estado. Además, nos era útil alterar la carpeta destino de los juegos con el objetivo de estructurar mejor el projecto. Por estas razones, decidimos cambiar ligeramente el código de recolección de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0820b98e",
   "metadata": {},
   "source": [
    "<div align=center>\n",
    "    <img src=\"../fotos/net_data_collector.png\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4678f67c",
   "metadata": {},
   "source": [
    "Como se puede observar, hemos realizado algunos cambios en la clase `GameDataCollector` con el objetivo de facilitar nuestros requerimientos particulares. En este caso, añadimos un campo llamado *evaluation* al diccionario con la información que aparecerá en el csv. Sin embargo, tuvimos que tener en cuenta que no todos los agentes contienen el atributo del que queremos hacer uso, por lo que añadimos una condición para comprobar de ese hecho.\n",
    "\n",
    "Además, mediante el argumento `output_dir`, podemos escoger donde queremos que los csv se guarden, lo que facilita el procesamiento posterior de los juegos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414f89f9",
   "metadata": {},
   "source": [
    "### **4.2. Tratamiento y entrenamiento**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81627642",
   "metadata": {},
   "source": [
    "Jugando 100 partidas, obtuvimos lo que consideramos suficiente información como para entrenar la red, sin embargo, las funciones definidas en el archivo `net.py` estaban diseñadas para un modelo de clasificación, mientras que el nuestro era de regresión. Por lo que tuvimos que cambiar varios aspectos de múltiples funciones para que se adaptasen a nuestras necesidades."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665a8bc4",
   "metadata": {},
   "source": [
    "En primer lugar, tuvimos que alterar la manera en la que los datos se cargaban dada la particularidad ya mencionada. Debido a esto, cambiamos la lectura del campo *action* por la del nuevo campo *evaluation*, de manera que obtuvieramos la información requerida. Sin embargo, esto no es todo lo que tuvimos que alterar. Debido al gran rango que observamos en los valores dados por la función de evaluación, tuvimos que normalizar dicho rango de manera que fuera más sencillo para la red predecir. Para esto, tomamos valores para la mínima evaluación posible así como para la máxima evaluación posible, de manera que pudieramos normalizar los valores obtenidos de los datos entre 0 y 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f11ced",
   "metadata": {},
   "source": [
    "Tras los anteriores cambios, pasamos a definir el modelo que usamos. Para su diseño, nos inspiramos en el tratamiento de los datos de entrada de la clase `PacmanNet` y la usamos como base para definir los pesos de nuestra red."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c82c1ed",
   "metadata": {},
   "source": [
    "<div align=center>\n",
    "    <img src=\"../fotos/net_model.png\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14cd811d",
   "metadata": {},
   "source": [
    "En nuestro caso, definimos los pesos como 3 capas lineales, la primera de ellas siendo una projección de las dimensiones del mapa a un espacio en $\\R^{64}$. A continuación, estos valores se pasan a otra capa lineal que los proyecta a un espacio de 32 dimensiones, antes de finalemente ser projectados a un único valor. En medio de estas capas lineales, hacemos uso de una función de activación conocida como **GELU**. La función **GELU** (*Gaussian Error Linear Unit*) se comporta de manera similar a la función **RELU**, que viene definida como:\n",
    "$$ReLU(x) = max(x, 0)$$\n",
    "Esto causa que para valores negativos, la función siempre tenga como valor 0. Sin embargo, los desarrolladores de **GELU** encontraron que ciertas redes neuronales entrenan mejor si se les permite ligeros valores negativos. Es por eso que esta función viene dada por la siguiente fórmula:\n",
    "$$GELU(x) = 0.5x \\cdot \\left(1 + tanh\\left(\\sqrt{\\frac{2}{\\pi}} \\cdot (x + 0.044715x^3)\\right)\\right)$$\n",
    "\n",
    "Además de lo anterior, añadimos un ligero *dropout* con el objetivo de prevenir **overfitting**, un suceso que ocurre cuando un modelo se entrena tanto en el set de entrenamiento que empieza a *memorizar* las respuestas en vez de aprender la lógica detrás de ellas.\n",
    "\n",
    "Finalmente, añadimos una función Sigmoide con el objetivo de poner las salidas en el rango 0 a 1, que es el mismo en el que se encuentran las entradas, así como hacemos uso de una capa de normalización para poner las entradas en un rango similar y excluir valores anómalos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a890524",
   "metadata": {},
   "source": [
    "Con los datos y el modelo preparados, podemos pasar al entrenamiento. Como ya se ha mencionado antes, el código proporcionado estaba pensado para el entrenamiento de un modelo de clasificación, mientras que nosotros estamos realizando regresión. Es debido a esto que tuvimos que adaptar varios aspectos de la función de entrenamiento. El primero de ellos fue la función de pérdida (*loss*) que originalmente era *CrossEntropyLoss*. Esta función está pensada para clasificación, por lo que la cambiamos por la *L1Loss*, también conocida como *MAE* (Mean Absolute Error). Decidimos usar esta función debido a los pequeños valores de la pérdida final así como para considerar todas las diferencias en valores, ya que estas de por sí eran pequeñas.\n",
    "\n",
    "En segundo lugar, tuvimos que cambiar el método por el cual medimos la precisión. Anteriormente, este medía cuantas clases estaban correctamente prececidas del total. Obviamente, este método solo tiene sentido en clasificación, mientras que siempre será 0 en regresión, donde incluso una pequeña diferencia causa que la respuesta no sea correcta. Debido a esto, decidimos cambiar el método de calcular la precisión, cambiándolo en su lugar por una función que mide cuantos valores de los predichos se encuentran a un $\\epsilon$ de diferencia de los valores esperados. Ajustando dicho $\\epsilon$ de acuerdo a nuestras necesidades, podemos ver como de bien la red está aprendiendo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a6d718",
   "metadata": {},
   "source": [
    "<div align=center>\n",
    "    <img src=\"../fotos/net_accuracy.png\"/>\n",
    "<div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9582db8",
   "metadata": {},
   "source": [
    "Finalmente, entrenamos la red en los 100 juegos mencionados anteriormente por 500 iteraciones con un *learning rate* de $0.005$. Usando la métrica de precisión mencionada antes, obtenemos alrededor de un 80% de precisión en el test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21fc5ca7",
   "metadata": {},
   "source": [
    "### **4.3. Evaluación y resultados**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964d4b6f",
   "metadata": {},
   "source": [
    "Tras entrenar el modelo, podemos hacer uso de él para sustituir la función de evaluación que desarrollamos anteriormente. Para realizar esto, escribimos una nueva función de evaluación que llamamos `neuralEvaluationFunction`. Esta función toma como entrada el estado actual de la partida y devuelve su evaluación, tal como se espera. Sin embargo, debemos hacer uso del modelo entrenado para ello. Dado que el modelo toma como entrada una matriz con índices para cada elemento presente en el mapa, transformamos el estado primeramente en ese tipo de mapa haciendo uso del método ya definido en `gamedata.py`:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d7b1b1",
   "metadata": {},
   "source": [
    "<div align=center>\n",
    "    <img src=\"../fotos/net_map_transform.png\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15159a73",
   "metadata": {},
   "source": [
    "Gracias a este código, transformamos el mapa de caractéres a uno numérico, con el que alimentamos al modelo. El modelo devuelve un valor entre 0 y 1, por lo que debemos devolverlo al rango $(-1500, 2500)$ que definimos previamente, siendo el valor resultante la evaluación de la red."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47ac735",
   "metadata": {},
   "source": [
    "En lo referente a los resultados dados por la red, encontramos que son insatisfactorios en el mejor caso, y pésimos en el peor. La red no consigue ganar ningún juego y muere debido a causas facilmente evitables, como un fantasma acercándose a pacman en una recta, con varias oportunidades para escapar. Además, la inferencia de la red es mucho más lenta que la llamada a la función de evaluación original, lo que limita la profundidad máxima a la que se puede llegar.\n",
    "\n",
    "Evaluando nuestras tácticas de entrenamiento, deducimos que quizás deberíamos haber incluido información sobre las posiciones de los fantasmas y/o otras variables en la entrada de la red, pero carecíamos del conocimiento de como hacerlo adecuadamente, así como del tiempo necesario para experimentar ampliamente con la red o la implementación de técnicas probadas en otros campos. Durante el entrenamiento, también encontramos que la precisión variaba ampliamente, entre valores de $60\\%$ y $85\\%$ aproximadamente, lo que indica que el modelo no estaba aprendiendo apropiadamente, sino más bien que estaba adivinando las respuestas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52eb0a12",
   "metadata": {},
   "source": [
    "## **5. TESTING**\n",
    "\n",
    "Expuestas todas las secciones previas, cabe presentar una serie de pruebas que responderán a los siguientes apartados:\n",
    "\n",
    "\n",
    "<ol>\n",
    "    <li>\n",
    "        Diferencia de tiempos \n",
    "    </li>\n",
    "    <li>\n",
    "        Prueba con semillas distintas\n",
    "    </li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a76037",
   "metadata": {},
   "source": [
    "### **5.1 Diferencia de Tiempos**\n",
    "\n",
    "Atendiendo a la implementación de MiniMax, así como la de Alpha-Beta (que implementa de por sí MiniMax) y el enfoque la Tabla de Transposición; se planteará la ejecución de una serie de pruebas en voluntad de determinar las diferencias temporales existentes entre las distintas configuraciones generables.\n",
    "\n",
    "Con objecto de fundar las pruebas a realizar, localizamos que cada posible combinación se ejecutará un total de 10 ocasiones por profundidad de búsqueda seleccionada y la métrica temporal resultante se presentará como la media muestral de los tiempos acontecidos por cada profundidad de búsqueda $a$ / $a \\in [1,6]$. Cabe señalar a su vez que trabajaremos bajo una **semilla fija (32)** y que las posibles configuraciones generables de metodologías serán las que siguen:\n",
    "\n",
    "1. MiniMax \n",
    "2. Alpha-Beta\n",
    "3. Tabla de Transposición\n",
    "\n",
    "\n",
    "A modo de ser rigurosos con la métrica de medida empleada, cabe señalar que la media muestral se presenta como un estimador insesgado de una muestra de datos extraída de una población de individuos que no conocemos en su totalidad. Con ello, encontramos que su desarrollo matemático es el que sigue para un set de muestra $S$:\n",
    "\n",
    "$$S = \\ \\left\\{x_1, x_2, x_3,...,x_n\\right\\}$$\n",
    "\n",
    "$$\\hat{\\mu} = \\frac{1}{|S|}\\sum_{i = 1}^{|S|} x_i$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9ec809",
   "metadata": {},
   "source": [
    "#### ·<u>***TABLA  REPRESENTATIVA***</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6813c5d7",
   "metadata": {},
   "source": [
    "Expuestos los fundamentos del experimento, cabe presentar una gráfica en representación de la evolución del consumo temporal medio por profundidad para cada una de las distintas configuraciones adoptadas. Si bien se especifica en la imagen, el eje de abscisas corresponderá con la profundidad de búsqueda tomada en plys y el de ordenadas aludirá a la cantidad de tiempo consumido en segundos por cada set de prueba. Véase pues la siguiente fotografía:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff81e2c6",
   "metadata": {},
   "source": [
    "<div align = center>\n",
    "    <img src ='../fotos/tests_grafica_tiempos.png'>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81665113",
   "metadata": {},
   "source": [
    "Tal y como podemos observar en el caso del eje de ordenadas, entendemos que su rango de valores ha sido sometido a un escalado logarítmico. Dicha operación se justifica ante la explosión en materia de tiempos que se desarrolla para profundidades de búsqueda crecientes y que implican que valores reducidos de las mismas acaben por proyectarse directamente sobre el eje. Consecuentemente, y dado que lo que pretendemos es poder observar las diferencias existentes entre configuraciones, dicha transformación se presenta como necesaria."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328fb3f0",
   "metadata": {},
   "source": [
    "#### ·<u>***CONCLUSIONES SOBRE OBSERVACIONES***</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b631b49",
   "metadata": {},
   "source": [
    "A modo de justificación de los resultados obtenidos de manera gráfica, entendemos que estos remiten a la cantidad de nodos o de estados concretos que las estrategias  necesitan visitar. Con ello, encontramos que el ránking asociado al peor rendimiento es el sigue:<br><br>\n",
    "\n",
    "\n",
    "**1.MINIMAX**\n",
    "\n",
    "Se presenta sin duda como la peor de las configuraciones adoptadas y expone un significativo incremento temporal respecto a las alternativas restantes. Dicho aumento o retardo viene justificado por la necesidad del algoritmo de explorar todas y cada una de las ramas del árbol a generar, no pudiendo descartar bifurcaciones no prometedoras o que claramente no conducen a ninguna jugada óptima.<br><br>\n",
    "\n",
    "\n",
    "\n",
    "**2.ALPHA-BETA**\n",
    "\n",
    "Será  en el panorama expuesto por parte de MiniMax que Alpha-Beta actúe como agente enriquecedor y  permita al primero podar o evitar visitar aquellas ramas dentro del árbol del búsqueda que, en base a criterios internos, no favorezcan el encontrar una jugada óptima. Dicho papel es el que queda reflejado en la gráfica de tiempos donde la caída  respecto a MiniMax es ciertamente significativa.<br><br>\n",
    "\n",
    "\n",
    "**3.TABLA DE TRANSPOSICIÓN**\n",
    "\n",
    "Finalmente, acudimos a la mejor de las opciones en términos temporales, esto es, la Tabla de Transposición. Es esa mejora acontecida la que viene dada por un almacenaje de los estados previos que provoca que, a medida que profundizamos en el árbol, es más probable que nos topemos ante situaciones que de manera previa ya habían sido computadas y guardadas; hecho el cual supone una reducción significativa del coste temporal.<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc9c934",
   "metadata": {},
   "source": [
    "### **5.2 Pruebas con Semillas Distintas**\n",
    "\n",
    "Con voluntad de evaluar cuantitativamente los resultados arrojados por parte de Pacman, atenderemos a la ejecución del código bajo diez semillas distintas como son las que siguen:\n",
    "\n",
    "$$Seeds = [912, 871, 3199, 3471, 2207, 1710, 1852, 2536, 581, 3333]$$\n",
    "\n",
    "\n",
    "Para cada una de las  semillas se elaborará un semiapartado componente en una serie de puntos como son los que siguen:\n",
    "\n",
    "1. Puntuación\n",
    "2. Estado final \n",
    "3. Tiempo consumido \n",
    "\n",
    "\n",
    "Cabe señalar que la configuración empleada para desempeñar la prueba se presentará como el uso combinado de Alpha-Beta y la Tabla de Transposición."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818ce437",
   "metadata": {},
   "source": [
    "#####   **<u>Seed 912</u>**\n",
    "\n",
    "1. Puntuación $\\rightarrow$ 1961 puntos\n",
    "\n",
    "2. Estado final $\\rightarrow$ win\n",
    "\n",
    "3. Tiempo consumido $\\rightarrow$ 15.079 s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ab6404",
   "metadata": {},
   "source": [
    "#####   **<u>Seed 871</u>**\n",
    " \n",
    "1. Puntuación $\\rightarrow$ 864\n",
    "\n",
    "2. Estado final $\\rightarrow$ lose\n",
    "\n",
    "3. Tiempo consumido $\\rightarrow$ 10.01 s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caff11c8",
   "metadata": {},
   "source": [
    "#####   **<u>Seed 3199</u>**\n",
    "\n",
    "1. Puntuación $\\rightarrow$ 1714\n",
    "\n",
    "2. Estado final $\\rightarrow$ win\n",
    "\n",
    "3. Tiempo consumido $\\rightarrow$ 9.627323865890503"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c9e488",
   "metadata": {},
   "source": [
    "#####   **<u>Seed 3471</u>**\n",
    "\n",
    "1. Puntuación $\\rightarrow$ 453\n",
    "\n",
    "2. Estado final $\\rightarrow$ lose\n",
    "\n",
    "3. Tiempo consumido $\\rightarrow$ 5.883488178253174"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8375247",
   "metadata": {},
   "source": [
    "#####   **<u>Seed 2207</u>**\n",
    "\n",
    "1. Puntuación $\\rightarrow$ 524\n",
    "\n",
    "2. Estado final $\\rightarrow$ lose\n",
    "\n",
    "3. Tiempo consumido $\\rightarrow$ 7.363305568695068"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa75bfbc",
   "metadata": {},
   "source": [
    "#####   **<u>Seed 1710</u>**\n",
    "\n",
    "1. Puntuación $\\rightarrow$ 858\n",
    "\n",
    "2. Estado final $\\rightarrow$ lose\n",
    "\n",
    "3. Tiempo consumido $\\rightarrow$ 10.581985473632812"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed8fbf0",
   "metadata": {},
   "source": [
    "#####   **<u>Seed 1852</u>**\n",
    "\n",
    "1. Puntuación $\\rightarrow$ -177\n",
    "\n",
    "2. Estado final $\\rightarrow$ lose\n",
    "\n",
    "3. Tiempo consumido $\\rightarrow$ 4.405104398727417"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a6d987",
   "metadata": {},
   "source": [
    "#####   **<u>Seed 2536</u>**\n",
    "\n",
    "1. Puntuación $\\rightarrow$ 1077\n",
    "\n",
    "2. Estado final $\\rightarrow$ lose\n",
    "\n",
    "3. Tiempo consumido $\\rightarrow$ 9.871320009231567"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873ae691",
   "metadata": {},
   "source": [
    "#####   **<u>Seed 581</u>**\n",
    "\n",
    "1. Puntuación $\\rightarrow$ 1769\n",
    "\n",
    "2. Estado final $\\rightarrow$ win\n",
    "\n",
    "3. Tiempo consumido $\\rightarrow$ 13.471442699432373"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5989800",
   "metadata": {},
   "source": [
    "#####   **<u>Seed 3333</u>**\n",
    "\n",
    "1. Puntuación $\\rightarrow$ 62\n",
    "\n",
    "2. Estado final $\\rightarrow$ lose\n",
    "\n",
    "3. Tiempo consumido $\\rightarrow$ 6.8131937980651855"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40dffe6",
   "metadata": {},
   "source": [
    "#####   **CIERRE**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d344d1",
   "metadata": {},
   "source": [
    "Como producto de los resultados anteriores podemos extraer una pareja de  métricas en representación del **win-rate** y la **puntuación media** obtenidos para las diez partidas jugadas. A su vez, cabe señalar que el espacio muestral generado para los estados finales se codifica como una cadena binaria $S$ tal que las victorias se representen como un $1$ y las derrotas como un $0$:\n",
    "\n",
    "$$S = \\left\\{1,0,1,0,0,0,0,0,1,0\\right\\}$$\n",
    "\n",
    "\n",
    "$$\\text{Win-Rate} = \\frac{1}{|S|}\\sum_{i = 1}^{|S|} S_i = \\frac{1}{3}$$\n",
    "<br><br>\n",
    "\n",
    "\n",
    "$$\\text{puntuacion partida} = \\left\\{1961, 864, 1714, 453, 524, 858, -177, 1077, 1769, 62 \\right\\}$$\n",
    "$$\\text{Puntuación media} = \\frac{1}{\\text{total partidas}} \\sum_{i = 1}^{10} \\text{(puntuacion partida)}_i = 910.5\\ puntos $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c20968",
   "metadata": {},
   "source": [
    "Como conclusión, podemos observar como pacman encuentra problemas para salir ganando, en este ejemplo particular consiguiéndolo solo 3 veces. Esto demuestra que pueden haber varios aspectos que no hemos considerado en la función de evaluación, o que nuestro diseño de esta tiene algún fallo fundamental. Corregir este suceso requeriría una gran dedicación de tiempo no solo a la corrección de las técnicas ya implementadas, sino el estudio de aquellas usadas por jugadores reales que, con suerte, podrían guiar nuestros esfuerzos hacia mejores puntuaciones y victorias.\n",
    "\n",
    "Como nota adicional, cabe destacar de que el porcentaje de victoria amortizado es entorno al $44\\%$, y si bien es mayor del mostrado por el pequeño ejemplo anterior, sigue sin desmentir las conclusiones enunciadas."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
